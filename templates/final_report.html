{% extends "base.html" %}
{% block content %}
    <link href="static/css/blog_post_1_style.css" rel="stylesheet" media="screen">
    <div class="row">
        <div class="col-md-2"></div>
        <div class="col-md-8">
            <div class="page-header center">
                <h1>Lineup Recommender <small>&laquo;Final Report&raquo;</small></h1>
            </div>

            For our final product, please click <a href="https://lineup-recommender.herokuapp.com/">here</a>!

            <h2>Abstract</h2>

            <h2>Part 1: Overview and Hypothesis</h2>
            <p> FanDuel and DraftKings have one-day fantasy sports contests. For Basketball, the contests require the user to enter with a lineup of 9 players that are playing in the games for that day. People enter these contests everyday by paying a fixed amount of money. Once the day’s games are done, the users with the lineups containing the best performing players (calculated using a linear combination of their individual stats), win a huge amount of money.
            </p>
            <p>
            With the aim of doing well on the daily FanDuel contests, we hypothesized the following:
            <ul>
                <li>We can attain more than 90% accuracy given enough historical data and the right selection of features.</li>
                <li>Projecting individual stats that contribute to a player’s overall performance can be better than directly projecting the fanduel score because we can choose only the relevant features for each specific stat.</li>
            </ul>
            </p>
            <hr>

            <h2>Part 2: Data Collection</h2>
            <p> We are using data from 3 different sources:
            <ul>
                <li> The NBA data we used is being scraped from <a href="http://stats.nba.com/">stats.nba.com</a>, which returns every player’s historical data. It contains the player scores, with each entry representing a particular player's score for a particular game. Each player's score is broken down into their 3-point and 2-point field goals made, freethrows, steals, blocks, rebounds, assists, and turnovers. Each score is associated with a player through that player's player id, which we convert into a slug in the form of 'nba-first_name-last_name':
                <img class="img-responsive" src="static/images/nba_stats.png"><br>
                <img class="img-responsive" src="static/images/nba_data.png"</li>
                <li><a href="https://www.numberfire.com/nba/daily-fantasy/daily-basketball-projections">NumberFire</a>, which provides details about the players that are playing in today’s games. We comb through the html of the page to get the player's name, salary, position, the opposing team, and whether the player is playing at home or not, and store this data in a double dictionary, where the key is the player name and the value is another dictionary containing all the fields previously mentioned.
                <img class="img-responsive" src="static/images/nf_data.png"></li>
                <li><a href="https://www.stattleship.com/">Stattleship</a>, which has information about each player not directly related to their game statistics. The data we are retrieving for each player is weight, height, name, and years of experience. The idea behind using this kind of data is that we would use these features in trying to predict different basketball statistics, like height for rebounds and weight for blocks, in trying to create as accurate of a prediction model as we can. 
                <img class="img-responsive" src="static/images/ss_data.png"></li>
            </ul>

            The data displayed above is after combination and cleaning which involved the following steps:
            <ul>
                <li>Create id maps to match players between the three data sources. Each data source keeps track of players, their features, and their gamelogs differently, using different player names and different ways to idenfity players. So this involved going through each of the data sources, creating a naming convention that would be used in generating the lineup, and using this convention to match the player data from all the sources to the same player. </li>
                <li>Accumulate data for the same player from different parts of each website. The NBA data is used for getting the gamelogs for each player as well as the positions for all the players. The Stattleship API is used in getting information about the player himself, and NumberFire is used to get the players that are playig in today's games.</li>
                <li>Remove games that the player did not play in, so that each player's gamelogs only contains the games that they played in. </li>
                <li>Remove bad values from gamelogs, such as invalid game dates and negative game statistics.</li>
            </ul>


            For every player, we collect the following information associated with that player:</p>
            <p>
                <ul>
                    <li>Gamelogs: a list of games they have played in, where each game has:
                        <ul>
                            <li>Time the game was held</li>
                            <li>Information on whether the game was played at home or away</li>
                            <li>The opponent team</li>
                            <li>Plus minus</li>
                            <li>How many times the player played in that game</li>
                            <li>Total rebounds score for the team the player is in</li>
                            <li>Total assists score</li>
                            <li>Total steals score</li>
                            <li>Total blocks score</li>
                            <li>Total turnovers score</li>
                            <li>Total points</li>
                        </ul>
                    </li>
                    <li>Position: a list of positions the player has, as some players have more than one position. For instance, Derek Williams plays in Point Forward and Small Forward.</li>
            </p>

            <h3>Challenges</h3>
            <p>Data Processing:</p>
            <ul>
                <li>Collecting  and combining the data from multiple sources (Stattleship, NumberFire and NBA) was time-consuming and complicated.</li>
                <li>Since player position can change per-game, we had no consistent source of per-game player position data. When we did include some sample positions, we additionally discovered that it had no significant impact on R<sup>2</sup> scores, or on final projections. Ultimately, we decided to not use player position in our projection features.</li>
            </ul>

            <p>Data Warehousing:</p>
            <p>
            We originally stored the cleaned and transformed data into a hosted Redis database. However, the latency of requesting all player data from a remote server ended up making our Redis database slower than using CSV files with our cleaned data.
            Thus, for our final projections, we switched back to locally hosted CSV files.
            </p>

            <p>
                One of the main challenges that we did not foresee is that data manipulation is very difficult, because of how rigid our data structure is; since there is not a single source that has all the features and player information we needed, we had to pull and consolidate data from three different sources, which involved a lot of data wrangling and entity resolution. If we wanted to add more features or even change how a feature is represented, we would have to change a large part of the data structure. An example of this would be if we tried to include hustle stats for each player. The hustle stats are hosted on a different website, which means we have to create another scraper to get the data and then link that data to each player, which sounds easy in theory but in reality these hustle stats are not easily associated with each player. 
            </p>

            <h2>Part 3: Regression and Projection</h2>
            <p> We decided to compare 5 different kinds of regression algorithms, and compare their projections:
                <ol>
                    <li>A linear regressor</li>
                    <li>A Lasso regressor (linear model using L1 regularization) with an alpha of 0.1</li>
                    <li>A random forest regressor using 1000 estimators (trees) and max splits of sqrt(#-of-features)</li>
                    <li>A support vector regressor with linear kernel, using a penalty coefficient of 1 and epsilon of 0.1</li>
                    <li>A support vector regressor with RBF kernel, using a penalty coefficient of 1 and epsilon of 0.1</li>
                </ol>
            </p>
            <p> For training data, we decided to use the following features to project each game statistic independently:
            <img class="img-responsive" src="static/images/features_labels.png">
            </p>
            <p> 
                Our linear, Lasso, and random forest regressors were trained on all player game data from the past 4 seasons.
                Our support vector regressors were trained on a single player’s game data (the player we are projecting) from the past 4 seasons. This was because SVM runtime is approximately O(#-of-observations<sup>2</sup>), forcing us to limit the number of training samples.
            </p>

            <p>
                Grouped bar chart that displays the projected stats:
            </p>
            <img class="img-responsive" src="static/images/regressor_barchart.png">

            <p>
                Based on each regressor's projections, we were able to see similarities and biases in overall projections.
                We found that RFR and SVR(Linear) consistently predicted higher stats than the others, indicating that they are biased to predict higher scores.
                Interestingly, Linear and Lasso were very similar in predictions. This is most likely due to them both being linear regressors; however, their similarities suggest that the L1 regularization has no impact on accuracy or bias of predictions.
    
            </p>
            <img class="img-responsive" src="static/images/regressor_table.png">
            <h4>Analysis</h4>

            <p>Joe Johnson's FanDuel projections changing over the past 4 years of collected data:</p>
            <img class="img-responsive" src="static/images/joe_johnson_linechart.png">
            <p>
                When we graphed player historic game data, we discovered that player performance was highly variable. In the long-term, we saw that player performance often stayed within certain bounds; a particular player often doesn't perform worse than a certain threshold, and often doesn't play better than a certain threshold.
                When predicting game-to-game performance, we saw that each player had very different performances from game to game, without a discernable pattern. This can be seen in the above line graph, where game-to-game scores often deviated from each other by 5 or greater points.
            </p>

            <p>R<sup>2</sup> Chart for Stephen Curry:</p>

            <img class="img-responsive" src="static/images/r2_chart.png">

            <p>
                When looking at the both SVR projections, we can see that they have negative R<sup>2</sup> values, particularly with directly projecting fanduel scores. This is due to the low amount of training data used for SVR, due to their slow runtime.
                The other regressors are closer to 0.4-0.5 R<sup>2</sup> scores, except when predicting steals, turnovers, and blocks. When analysing these three statistics, we determined that those are very dependent on opponent team performance. Since we only look at a given player's historic features, and not the opposing player performance, these stats are predicted less accurately.
                Other than the SVRs, RFR has the lowest R<sup>2</sup> scores for all projections.
                These resulting scores suggest that using a linear regressor, with or without L1 regularization, has the best results for projecting.
            </p>

            <p>
                Once we decided on using a linear regressor, we wanted to explore whether using clustering impacted accuracy. We extended our FeatureProjector class to a ClusteringFeatureProjector. This new projector would additionally cluster each player based on their average FanDuel scores. Once each cluster is determined, we fit regressors for each game stat and each cluster; this means each regressor is only trained on clusters of players with similar performance. We hoped that by only training on similar players, we could better tailor our player projections to levels of similar performance. However, when looking at our R<sup>2</sup> scores:
            </p>

            <table class="table table-striped" border="1" cellpadding="3" cellspacing="3">
                <tr>
                    <th>>Game Stat</th>
                    <th>No Clustering</th>
                    <th>Clustering (1st cluster)</th>
                    <th>Clustering (2nd cluster)</th>
                    <th>Clustering (3rd cluster)</th>
                </tr>
                <tr>
                    <td>Assists</td>
                    <td>0.523</td>
                    <td>0.360</td>
                    <td>0.226</td>
                    <td>0.516</td>
                </tr>
                <tr>
                    <td>Blocks</td>
                    <td>0.216</td>
                    <td>0.192</td>
                    <td>0.094</td>
                    <td>0.255</td>
                </tr>
                <tr>
                    <td>Points</td>
                    <td>0.468</td>
                    <td>0.235</td>
                    <td>0.163</td>
                    <td>0.291</td>
                </tr>
                <tr>
                    <td>Rebounds</td>
                    <td>0.453</td>
                    <td>0.353</td>
                    <td>0.210</td>
                    <td>0.413</td>
                </tr>
                <tr>
                    <td>Steals</td>
                    <td>0.132</td>
                    <td>0.065</td>
                    <td>0.052</td>
                    <td>0.079</td>
                </tr>
                <tr>
                    <td>Turnovers</td>
                    <td>0.248</td>
                    <td>0.109</td>
                    <td>0.079</td>
                    <td>0.147</td>
                </tr>
            </table>

            <p>
                As seen above, the clusters all performed worse than the linear regressor without clustering. The main reason, we discovered, was the low amount of sample used for each cluster. Since the players were now divided amongst each 3 clusters, each linear regressor had lass data to use than the no clustering linear regressor. We decided that using ano clustering linear regressor with the full historic data set was the best solution.
            </p>

            <h3>Challenges</h3>
            Feature Flexibility:
            <ul>
                <li>We were not able to try all the different combinations of features we were hoping to for projections because it is very difficult to get data about new features. It might involve having to scrape a different website or page and cleaning and then adapting it to our existing data structures.</li>
            </ul>
            <hr>

            <h2>Part 4: Finding the Optimal Lineup</h2>
            <p>Fanduel has daily contests for the games that are occurring on that day. In the below image, you can see the information about one such contest.</p>
            <img class="img-responsive" src="static/images/fanduel_contest_information.png"></img>
            <p>As seen above, the user needs to pick 9 players (collectively called a lineup) from the 3 games to enter the contest with.<br>Below is an image of the screen after I built my lineup.</p>

            <img class="img-responsive" src="static/images/fanduel_contest_entry.png"></img>
            <p>Two details are important to understanding how a lineup works:
            <ol>
                <li>A player can be playing in one of these positions - Point Guard (PG), Shooting Guard (SG), Small Forward (SF), Power Forward (PF) or Center (C).</li>
                <li>Each player has a salary that is not their real salary but their fantasy salary assigned to them by Fanduel based on how well they have been performing.</li>
            </ol>

            </p>
            <p>
            Given the above information there are two constraints to keep in mind when creating the lineup:
            <ol>
                <li>The user needs to choose two players for each of the PG, SG, SF, and PF positions and one player for the C position. This adds up to a total of 9 players.</li>
                <li>The sum of the salaries of the 9 players cannot exceed the salary cap which in the above contest was $60,000 (it almost always is $60,000).</li>
            </ol>

            We first implemented the traditional dynamic programming approach to solving a knapsack problem. But, this does not take into account the additional constraints. After searching a lot for packages that might do this on python, we finally found openopt (a python module for numerical optimization). Although openopt is not documented online, we tinkered around a lot and finally got it to work with our constraints. Our optimal lineup for the games on April 18th is below. On looking back, this turned out to be the 37th best lineup for that day. This lineup would have won the user a significant amount of money on most contests.
            </p>
            <img class="img-responsive" src="static/images/optimal_lineup.png">

            <h3>Challenges</h3>
            Optimization:
            <ul>
                <li>Going over all possible lineups never finishes running because even on a day when just 50 players are playing there are a total of 2505433700 possible lineups. On most days there are more than 100 players which would be 1902231808400 lineups to go over.
                <li>Finding and working with openopt was very difficult and took a long time to figure out.</li>
            </ul>
            <hr>

            <h2>Part 5: Final Product vs. Project Proposal</h2>

            <p>
                We met our 75% goal of creating a framework for projecting fantasy scores. We collected player data over 4 seasons, instead of 5, and used this data to project scores for all the players playing today. Then taking inspiration from the knapsack problem, we created an ideal, optimal lineup consisting of 9 players. We tried different machine learning algorithms in the process of trying to increase the accuracy of our prediction model, but were unable to get the 90%+ accuracy that we originally wanted in our proposal. After comparing all the results from various regressors (like logistic regression, linear regression, SVR, lasso regression, and random forest regression), linear regression (no clustering) had the best R<sup>2</sup> score, suggesting that it had fit the data better than the others. Therefore, we are using linear regression instead of logistic regression. While we were not able to get better accuracy, we were able to evaluate different regression techniques and find the most optimal projector. Our main obstacle to accuracy was due to the variability of game-to-game player performance, and lack of data to create more complex feature sets. Because of the time spent dealing with all of the challenges that arose in doing this project, were were unable suggest multiple lineups, but extending our code to return multiple high variance lineups would not be overly difficult.
            </p>

            <hr>

            <h2>Part 6: Future Work</h2>
            <ul>
            <li>To improve the R<sup>2</sup>-score, the current ideas we have are:
                <ol>
                    <li>Find a more specific set of data (like hustle stats, etc.) for predicting steals and blocks.
                    <li>Gather additional opponent team data as features when predicting steals, blocks, and turnovers.
                    <li>Use rolling averages over games for more features (like minutes played and plus-minus).
                </ol>
            <li>Replace high salaried players with low salaried high variance players to beat out most traditional lineups.
            <li>Create a fully fledged website. Since we have a lineup optimizer in place, we can provide an optimzation tool on the webpage itself where any user can upload their own data and ask for the optimal lineup. We found a website that does this but funnily enough, they do not suggest the optimal lineup. Our program on the other hand did find the optimal lineup (the one with a total projected score of 289 as opposed to their 286).<br><br>
            <img class="img-responsive" src="static/images/rotoraider_lineup.png"><br>
            <img class="img-responsive" src="static/images/lineup-recommender_lineup.png">



            <!--<hr> In case you haven't noticed, this is a horizontal rule. It makes a horizontal line in the page. -->
        <div class="col-md-2"></div>
    </div> 
{% endblock %}